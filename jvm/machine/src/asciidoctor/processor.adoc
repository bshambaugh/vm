== Processor Structures

image::processor-stack.png[float="left",width=150]

The programs of the mm-ADT virtual machine are _types_. From a simple set of canonical types (_ctypes_), derived types (_dtypes_) of arbitrary complexity can be constructed using instructions from the VM's instruction set architecture. Type construction yields a https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)[graph] containing type vertices and instruction edges called a _type graph_. The type graph is the internal data structure used by the mm-ADT VM to not only encode types, but also to compile (transformation) and execute (enumeration) them.

mm-ADT compliant *processors* ground the abstract mm-ADT VM to the underlying physical machine (whether on a a single machine, via multiple threads, or across a compute cluster). At the bottom of this "process stack", the natural world's physics provides the baseline dynamics (a "_ptype_" so to speak). Finally, atop this stack of abstraction is the mm-ADT VM's general-purpose, register-based machines known as the *traversers*.

IMPORTANT: Distributed mm-ADT processors can yield on the order of millions of traversers during a single program evaluation. Conceptually, a processor is responsible for coordinating a https://en.wikipedia.org/wiki/Swarm_intelligence[_traverser swarm_], where the result of an mm-ADT program is the aggregate data locations of all the halted traversers.

.Products and Coproducts
****
https://en.wikipedia.org/wiki/Category_theory[Category theory] is the study of structure via manipulations that expose (or generate) other structures. Two important category theoretic concepts used throughout this section are *products* and *coproducts*.

image::product.png[float="left",width=220]

A https://en.wikipedia.org/wiki/Product_(category_theory)[product] is any object defined in terms of it's accessible component objects. That is, from a single object, via \$\pi_n\$ projection morphisms, the product is decomposed into it's constituent parts.

image::coproduct.png[float="right",width=220]

A https://en.wikipedia.org/wiki/Coproduct[coproduct] is any object defined in terms the component objects used to construct it. That is, from many objects, via \$\iota_n\$ injection morphisms, a coproduct can be composed from constituent parts.

Along with these decomposition (and composition) morphisms, there exists an https://en.wikipedia.org/wiki/Isomorphism[isomorphism] between any two products (or coproducts) should they project (or inject) to the same component objects. That is, product and coproduct equality are defined via component equality.
****

=== Traverser

A traverser (`trav`) is a _product_ with the following three \$\pi\$-projections:

image::traverser-product.png[float="right",width=350]

. `[pc]` (\$\pi_1\$): the https://en.wikipedia.org/wiki/Program_counter[*program counter*] denotes the traverser's current location in the program (type).
. `[dc]` (\$\pi_2\$): the https://en.wikipedia.org/wiki/Pointer_(computer_programming)[*data counter*] denotes the traverser's current location in the data (value -- or type during compilation).
. `[state]` (\$\pi_3\$): the local read/write https://en.wikipedia.org/wiki/Processor_register[*registers*] of the traverser provide a memory structure useful when writing more complicated programs.

Traversers are used in the following two situations:

1. *Compilation*: A traverser walks a type graph as directed by the type graph in order to generate another type graph. The resultant type graph typically contains more information (type inference) and/or more efficient types for expressing the same computation (type optimization).

image::trav-compilation.png[align="center",width=65%]

2. *Evaluation*: A traverser walks a value graph as directed by a type graph in order to generate another value graph. The resultant values are the referents of the program's specified type.

image::trav-evaluation.png[align="center",width=35%]

Compilation and evaluation are both accomplished using the same graph traversal algorithm.

...

//image::traverser-fold.png[align="center",width=80%]

&nbsp;

// image::traverser.png[align="center",width=550]

==== Instruction Evaluation

An `inst` can be applied to a traverser via:

\[
\texttt{b<=a[inst]}: T(A) \rightarrow T(B).
\]

However, this simple specification is further complicated by instruction arguments. For example, assume the following dtype generated from the `int` ctype via the single instruction `[plus,[mult,2]]`.

[source]
----
mmlang> int[plus,[mult,2]]
==>int[plus,int[mult,2]]
mmlang> 10[plus,[mult,2]]
==>30
----

image::instruction-arguments.png[align="center",width=90%]

Every instruction argument that is a type is first resolved by applying the type. Once all arguments have been evaluated, the parent instruction can execute. In this way, every type-argument instruction has internal blocking branches.


=== Instruction Classes

==== Branching

The `[branch]` instruction is a general-purpose instruction for creating and merging parallel streams of objects. All other branching instructions are founded on `[branch]` and extend it with added usability-parametrization. In general, all branching instructions can be understood as generating a product (*splitting*) and then generating a co-product (*merging*).

image::branch-prod-coprod.png[align="center",width=75%]

When a traverser at an \$\tt{obj} \in A\$ arrives at `[branch]`, the traverser is split across the respective internal types -- called _branches_. Splitting is a cloning process by which a product is formed and then each component of the product is projected to each respective branch via \$\pi_n\$.

\[\texttt{split}: A \rightarrow A \times \ldots \times A\]

image::branch-traversers.png[float="left",width=600]

Every branch can operate independently, where no global communication is required between branches. This is an important feature of `[branch]` and the branch instructions in general because each branch can be isolated and migrated for physical distribution and parallelization. All other instructions that make use of internal types for parametrization do not enjoy this feature.

Finally, the resultant traversers of each individual branch are then summed via \$\iota_n\$ to yield a single stream co-product of outgoing traversers.

\[\texttt{merge}: (B \times \ldots \times D) \rightarrow (B + \ldots + D)\]

===== Branching Specifications

There are two ways of programming a `[branch]` instruction.

. Using a `rec` structure where the keys are `{0}`-predicate filters and the values are the branch transformations.
. Using a `lst` structure where the values are the branch transformations.

Every `lst`-form can be expressed as a `rec`-form via and every `rec`-form can be expressed as a `lst`-form. The general rule for transformation is detailed in the source fragment below.

[source]
----
[branch,[[a];[b];[c]]]    => [branch,[x:a,y:b,z:c]]
[branch,rec[x:a,y:b,z:c]] => [branch,[[is,x][a];[is,y][b];[is,z][c]]]
----

The `[branch]` instruction takes a single `rec`-type argument. The record keys are `{0}`-predicates where if the incoming `obj` matches the key, then the `obj` is processed by the value. _Every key_ that matches has it's respective value processed for the incoming `obj`.

\[
\tt x[branch]:[tk_1:tv_1] \times \ldots \times [tk_n:tv_n] \rightarrow \biguplus_{i \in 1 \to n} x[tv_i] \; \text{iff} \; x[tk_i][q] \neq 0
\]


=== Processor Implementations