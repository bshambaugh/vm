:imagesdir: ./images/processor
== Processor Structures

The programs of the mm-ADT virtual machine are _types_. From a simple set of canonical types (_ctypes_), derived types (_dtypes_) of arbitrary complexity can be constructed using instructions from the VM's instruction set architecture. Type construction yields a https://en.wikipedia.org/wiki/Directed_graph[directed labeled graph] containing type-vertices and instruction-edges called a _type graph_. The type graph is the internal data structure used by the mm-ADT VM to not only compose types (encode), but also to compile (transform/optimize) and evaluate (enumerate) them.

image::processor-stack.png[float="right",width=150]

Type composition, compilation, and execution are carried out by general-purpose, register-based machines called *traversers*. The traverser algorithm is driven by mm-ADT compliant *processors*. Processors grounds the mm-ADT VM to the physical machine (whether on a a single machine, via multiple threads, or across a compute cluster), where ultimately, at the bottom of this "process stack," the natural world's physics provides the baseline dynamics (a "_ptype_" so to speak).

This section details the specifics of the relationships between types, traversers, and processors.
&nbsp;

&nbsp;

.Products and Coproducts
****
https://en.wikipedia.org/wiki/Category_theory[Category theory] is the study of structure via manipulations that expose (or generate) other structures. Two important category theoretic concepts used throughout this section are *products* and *coproducts*.

image::product.png[float="left",width=220]

A https://en.wikipedia.org/wiki/Product_(category_theory)[product] is any object defined in terms of it's accessible component objects. That is, from a single object, via \$\pi_n\$ projection morphisms, the product is decomposed into it's constituent parts.

image::coproduct.png[float="right",width=220]

A https://en.wikipedia.org/wiki/Coproduct[coproduct] is any object defined in terms the component objects used to construct it. That is, from many objects, via \$\iota_n\$ injection morphisms, a coproduct can be composed from constituent parts.

Along with these decomposition (and composition) morphisms, there exists an https://en.wikipedia.org/wiki/Isomorphism[isomorphism] between any two products (or coproducts) should they project (or inject) to the same component objects. That is, product and coproduct equality are defined via component equality.
****

=== Traverser

A traverser (`trav`) is a _product_ with the following three \$\pi\$-projections:

image::trav-product.png[float="right",width=350]

. \$\pi_1: Tr \rightarrow T\$: the https://en.wikipedia.org/wiki/Program_counter[program counter] denotes the traverser's current location in the program (type).
. \$\pi_2: Tr \rightarrow (T \cup V)\$: the https://en.wikipedia.org/wiki/Pointer_(computer_programming)[data counter] denotes the traverser's current location in the data (value -- or type during compilation).
. \$\pi_3: Tr \rightarrow (\Sigma \times (T \cup V))^n\$): the local read/write https://en.wikipedia.org/wiki/Processor_register[registers] of the traverser provide a memory structure useful when writing programs that require historic data (value paths), accumulators (mutating seeds), etc.

IMPORTANT: An mm-ADT `obj` is the co-product `obj = type + value`. Thus, the \$\pi_2\$-projection entails that traversers can process types as well as values.

Traversers are used in the following three situations:

. *Composition*: A traverser with an untyped `obj`-\$pi_1\$ (i.e. an instruction list) and a `obj`-\$pi_2\$ (i.e. the terminal object), walks the list of instructions to generate an unoptimized mm-ADT program (type) that is well-typed and well-quantified (https://en.wikipedia.org/wiki/Type_inference[type inference]).
+
image::trav-compose.png[align="center",width=90%]

. *Compilation*: A traverser with a type-\$pi_1\$ and a ctype-\$pi_2\$ evaluates the instructions of the type to generate a potentially more efficient type, with respective storage and processor provide instruction integration (https://en.wikipedia.org/wiki/Program_optimization[type optimization]). This process repeats with the resultant \$\pi_2\$ becoming the \$\pi_1\$ at the next iteration until a type https://en.wikipedia.org/wiki/Fixed_point_%28mathematics%29[fix point] is reached.
+
image::trav-compilation.png[align="center",width=70%]

. *Evaluation*: A traverser with a type-\$pi_1\$ and a value-\$pi_2\$ evaluates the type instructions to yield the referent values of the program's specified type (https://en.wikipedia.org/wiki/Execution_(computing)[type enumeration]).
+
image::trav-evaluation.png[align="center",width=40%]

//image::traverser-fold.png[align="center",width=80%]

&nbsp;

// image::traverser.png[align="center",width=550]

==== Instruction Evaluation

Every mm-ADT instruction denotes a https://en.wikipedia.org/wiki/Unary_function[unary function], but mm-ADT instructions themselves may contain zero, one, or multiple sub-expressions as arguments. At the mm-ADT type-level, mm-ADT instructions are \$n\$-ary computable relations, where through currying and stream semantics, ultimately, unary functions are realized.

===== n-Ary Instructions

Instructions that have no arguments and which map one input to one output are *nullary instructions*. For example, `[neg]` (negative/negate) is a nullary instruction in the type `int[neg]` denoting the unary function
\[
\begin{array}.
  \texttt{neg} &:& \mathbb{N} \rightarrow \mathbb{N} \\
  \texttt{neg}(x) &\mapsto& -x.
\end{array}
\]

The *unary instruction* `[plus,2]` in `int[plus,2]` is evaluated by the processor as the unary function
\[
\begin{array}.
  \texttt{plus_2} &:& \mathbb{N} \rightarrow \mathbb{N} \\
  \texttt{plus_2}(x) &\mapsto& x + 2.
\end{array}
\]

Instructions can have arguments that are dependent on the incoming `obj` (i.e. the unary function argument). For instance, the unary instruction `[plus,[mult,3]]` in `int[plus,int[mult,3]]` denotes the unary function
\[
\begin{array}.
  \texttt{plus_mult_3} &:& \mathbb{N} \rightarrow \mathbb{N} \\
  \texttt{plus_mult_3}(x) &\mapsto& x + (x * 3).
\end{array}
\]

Finally, as example instruction when the domain and range differ, `[gt,[plus,[id]]]` in
\[
\tt{bool<=int[gt,int[plus,int[id]]]}
\]
denotes the unary function
\[
\begin{array}.
\texttt{gt_plus_id} &:& \mathbb{N} \rightarrow \{\texttt{true} \cup \texttt{false}\} \\
\texttt{gt_plus_id}(x) &\mapsto& x > (x + x).
\end{array}
\]

NOTE: Distributed mm-ADT processors can yield on the order of millions of traversers during a single program evaluation. Conceptually, a processor is responsible for coordinating a https://en.wikipedia.org/wiki/Swarm_intelligence[_traverser swarm_], where the result of an mm-ADT program is the aggregate data locations of all the halted traversers.


===== n-Ary Relations

However, this simple specification is further complicated by instruction arguments. For example, assume the following dtype generated from the `int` ctype via the single instruction `[plus,[mult,2]]`.

[source]
----
mmlang> int[plus,[mult,2]]
==>int[plus,int[mult,2]]
mmlang> 10[plus,[mult,2]]
==>30
----

image::instruction-arguments.png[align="center",width=90%]

Every instruction argument that is a type is first resolved by applying the type. Once all arguments have been evaluated, the parent instruction can execute. In this way, every type-argument instruction has internal blocking branches.


=== Instruction Classes

==== Branching

The `[branch]` instruction is a general-purpose instruction for creating and merging parallel streams of objects. All other branching instructions are founded on `[branch]` and extend it with added usability-parametrization. In general, all branching instructions can be understood as generating a product (*splitting*) and then generating a co-product (*merging*).

image::branch-prod-coprod.png[align="center",width=75%]

When a traverser at an \$\tt{obj} \in A\$ arrives at `[branch]`, the traverser is split across the respective internal types -- called _branches_. Splitting is a cloning process by which a product is formed and then each component of the product is projected to each respective branch via \$\pi_n\$.

\[\texttt{split}: A \rightarrow A \times \ldots \times A\]

image::branch-traversers.png[float="left",width=600]

Every branch can operate independently, where no global communication is required between branches. This is an important feature of `[branch]` and the branch instructions in general because each branch can be isolated and migrated for physical distribution and parallelization. All other instructions that make use of internal types for parametrization do not enjoy this feature.

Finally, the resultant traversers of each individual branch are then summed via \$\iota_n\$ to yield a single stream co-product of outgoing traversers.

\[\texttt{merge}: (B \times \ldots \times D) \rightarrow (B + \ldots + D)\]

===== Branching Specifications

There are two ways of programming a `[branch]` instruction.

. Using a `rec` structure where the keys are `{0}`-predicate filters and the values are the branch transformations.
. Using a `lst` structure where the values are the branch transformations.

Every `lst`-form can be expressed as a `rec`-form via and every `rec`-form can be expressed as a `lst`-form. The general rule for transformation is detailed in the source fragment below.

[source]
----
[branch,[[a];[b];[c]]]    => [branch,[x:a,y:b,z:c]]
[branch,rec[x:a,y:b,z:c]] => [branch,[[is,x][a];[is,y][b];[is,z][c]]]
----

The `[branch]` instruction takes a single `rec`-type argument. The record keys are `{0}`-predicates where if the incoming `obj` matches the key, then the `obj` is processed by the value. _Every key_ that matches has it's respective value processed for the incoming `obj`.

\[
\tt x[branch]:[tk_1:tv_1] \times \ldots \times [tk_n:tv_n] \rightarrow \biguplus_{i \in 1 \to n} x[tv_i] \; \text{iff} \; x[tk_i][q] \neq 0
\]


=== Processor Implementations