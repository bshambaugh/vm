:imagesdir: ./images/processor
== Processor Structures

The programs of the mm-ADT virtual machine are _types_. From a set of canonical types (_ctypes_), derived types (_dtypes_) of arbitrary complexity can be constructed using instructions from the VM's instruction set architecture. Every mm-ADT type is isomorphic to a https://en.wikipedia.org/wiki/Directed_graph[directed labeled graph] containing type-vertices and instruction-edges called the _type graph_. The type graph is the internal data structure used by the mm-ADT VM to not only compose types (encode), but also to compile (transform/optimize) and evaluate (enumerate) them.

image::processor-stack.png[float="right",width=150]

Type composition, compilation, and execution are carried out a thread of execution called a *process*. All processes are managed by an integerated mm-ADT compliant *processor*.  Processors ground the mm-ADT VM to the physical machine (whether on a a single machine, via multiple threads, or across a compute cluster), where ultimately, at the bottom of this "process stack," the natural world's physics provides the baseline dynamics (a "_ptype_" so to speak).

This section details the specifics of the relationships between types, values, and processors

=== Processes

Processors are used in the following three situations:

. *Composition*: A process with an untyped `obj`-\$pi_1\$ (i.e. an instruction list) and a `obj`-\$pi_2\$ (i.e. the terminal object), walks the list of instructions to generate an unoptimized mm-ADT program (type) that is well-typed and well-quantified (https://en.wikipedia.org/wiki/Type_inference[type inference]).
+
image::trav-composition.png[align="center",width=90%]

. *Compilation*: A traverser with a type-\$pi_1\$ and a ctype-\$pi_2\$ evaluates the instructions of the type to generate a potentially more efficient type, with respective storage and processor provide instruction integration (https://en.wikipedia.org/wiki/Program_optimization[type optimization]). This process repeats with the resultant \$\pi_2\$ becoming the \$\pi_1\$ at the next iteration until a type https://en.wikipedia.org/wiki/Fixed_point_%28mathematics%29[fix point] is reached.
+
image::trav-compilation.png[align="center",width=70%]

. *Evaluation*: A traverser with a type-\$pi_1\$ and a value-\$pi_2\$ evaluates the type instructions to yield the referent values of the program's specified type (https://en.wikipedia.org/wiki/Execution_(computing)[type enumeration]).
+
image::trav-evaluation.png[align="center",width=40%]

//image::traverser-fold.png[align="center",width=80%]

&nbsp;

// image::traverser.png[align="center",width=550]

==== Instruction Evaluation

Every mm-ADT instruction denotes a https://en.wikipedia.org/wiki/Unary_function[unary function], but mm-ADT instructions themselves may contain zero, one, or multiple sub-expressions as arguments. At the mm-ADT type-level, mm-ADT instructions are \$n\$-ary computable relations, where through currying and stream semantics, ultimately, unary functions are realized.

===== n-Ary Instructions

Instructions that have no arguments and which map one input to one output are *nullary instructions*. For example, `[neg]` (negative/negate) is a nullary instruction in the type `int[neg]` denoting the unary function
\[
\begin{array}.
  \texttt{neg} &:& \mathbb{N} \rightarrow \mathbb{N} \\
  \texttt{neg}(x) &\mapsto& -x.
\end{array}
\]

The *unary instruction* `[plus,2]` in `int[plus,2]` is evaluated by the processor as the unary function
\[
\begin{array}.
  \texttt{plus_2} &:& \mathbb{N} \rightarrow \mathbb{N} \\
  \texttt{plus_2}(x) &\mapsto& x + 2.
\end{array}
\]

Instructions can have arguments that are dependent on the incoming `obj` (i.e. the unary function argument). For instance, the unary instruction `[plus,[mult,3]]` in `int[plus,int[mult,3]]` denotes the unary function
\[
\begin{array}.
  \texttt{plus_mult_3} &:& \mathbb{N} \rightarrow \mathbb{N} \\
  \texttt{plus_mult_3}(x) &\mapsto& x + (x * 3).
\end{array}
\]

Finally, as example instruction when the domain and range differ, `[gt,[plus,[id]]]` in
\[
\tt{bool<=int[gt,int[plus,int[id]]]}
\]
denotes the unary function
\[
\begin{array}.
\texttt{gt_plus_id} &:& \mathbb{N} \rightarrow \{\texttt{true} \cup \texttt{false}\} \\
\texttt{gt_plus_id}(x) &\mapsto& x > (x + x).
\end{array}
\]

The above unary function is evaluated via the nested mm-ADT instruction, where the \$\Delta_n\$ product projections refer to the diagonal of the `obj` (clone) and the \$arg_n\$ products projections denote the arguments to the subsequent instruction.

image::int_gt_plus_id.png[align="center",width=100%]

===== n-Ary Relations

NOTE: Distributed mm-ADT processors can yield on the order of millions of traversers during a single program evaluation. Conceptually, a processor is responsible for coordinating a https://en.wikipedia.org/wiki/Swarm_intelligence[_traverser swarm_], where the result of an mm-ADT program is the aggregate data locations of all the halted traversers.


=== Instruction Classes

==== Branching

The `[branch]` instruction is a general-purpose instruction for creating and merging parallel streams of objects. All other branching instructions are founded on `[branch]` and extend it with added usability-parametrization. In general, all branching instructions can be understood as generating a product (*splitting*) and then generating a co-product (*merging*).

image::branch-prod-coprod.png[align="center",width=75%]

When a traverser at an \$\tt{obj} \in A\$ arrives at `[branch]`, the traverser is split across the respective internal types -- called _branches_. Splitting is a cloning process by which a product is formed and then each component of the product is projected to each respective branch via \$\pi_n\$.

\[\texttt{split}: A \rightarrow A \times \ldots \times A\]

image::branch-traversers.png[float="left",width=600]

Every branch can operate independently, where no global communication is required between branches. This is an important feature of `[branch]` and the branch instructions in general because each branch can be isolated and migrated for physical distribution and parallelization. All other instructions that make use of internal types for parametrization do not enjoy this feature.

Finally, the resultant traversers of each individual branch are then summed via \$\iota_n\$ to yield a single stream co-product of outgoing traversers.

\[\texttt{merge}: (B \times \ldots \times D) \rightarrow (B + \ldots + D)\]

===== Branching Specifications

There are two ways of programming a `[branch]` instruction.

. Using a `rec` structure where the keys are `{0}`-predicate filters and the values are the branch transformations.
. Using a `lst` structure where the values are the branch transformations.

Every `lst`-form can be expressed as a `rec`-form via and every `rec`-form can be expressed as a `lst`-form. The general rule for transformation is detailed in the source fragment below.

[source]
----
[branch,[[a];[b];[c]]]    => [branch,[x:a,y:b,z:c]]
[branch,rec[x:a,y:b,z:c]] => [branch,[[is,x][a];[is,y][b];[is,z][c]]]
----

The `[branch]` instruction takes a single `rec`-type argument. The record keys are `{0}`-predicates where if the incoming `obj` matches the key, then the `obj` is processed by the value. _Every key_ that matches has it's respective value processed for the incoming `obj`.

\[
\tt x[branch]:[tk_1:tv_1] \times \ldots \times [tk_n:tv_n] \rightarrow \biguplus_{i \in 1 \to n} x[tv_i] \; \text{iff} \; x[tk_i][q] \neq 0
\]


=== Processor Implementations